import pandas as pd
import numpy as np
from scipy.signal import find_peaks
import os

    # 2ë‹¨ê³„ì—ì„œ ìƒì„±ëœ feature_dfë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
import matplotlib.pyplot as plt

# --- ì½”ë“œ ì‹¤í–‰ ì „ ì„¤ì • ---
# ê°€ì§€ê³  ê³„ì‹  ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.
# ì˜ˆ: FILE_PATH = 'C:/Users/MyUser/Documents/my_real_data.csv'
FILE_PATH = 'sensor_log_2025-09-26_03-40-56.csv'

# --- ì˜ˆì œ ë°ì´í„° ìƒì„± (ìˆ˜ì •ë¨) ---
def create_dummy_data(filename):
    """í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°€ìƒ ì„¼ì„œ ë°ì´í„° CSV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. (ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½)"""
    if os.path.exists(filename):
        print(f"'{filename}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ìƒˆë¡œ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
        
    print(f"'{filename}' ì˜ˆì œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    num_points = 500
    
    # ê¸°ë³¸ ë…¸ì´ì¦ˆ ìƒì„±
    noise = lambda: np.random.normal(0, 0.05, num_points)
    
    # ê° ì¶• ë°ì´í„° ì´ˆê¸°í™”
    ax, ay, az = noise(), noise(), np.ones(num_points) + noise() # í‰ì§€ (Zì¶•ì— ì¤‘ë ¥ê°€ì†ë„)
    gx, gy, gz = noise(), noise(), noise()
    mx, my, mz = noise(), noise(), noise()
    
    # êµ¬ê°„ë³„ íŠ¹ì§• ë°ì´í„° ì‚½ì…
    # 1. ê²½ì‚¬ë¡œ (100-200 êµ¬ê°„)
    ay[100:200] += 0.3 # ì•ìœ¼ë¡œ ê¸°ìš¸ì–´ì§
    az[100:200] -= 0.3
    
    # 2. ê³„ë‹¨ (300-400 êµ¬ê°„)
    for i in range(300, 400, 10): # 10ê°œ ë°ì´í„°ë§ˆë‹¤ ì¶©ê²© ë°œìƒ
        az[i:i+3] += 1.5 # ê°•í•œ ìˆ˜ì§ ì¶©ê²©
        
    # 3. ë‹¨ì°¨ (450 êµ¬ê°„)
    az[450:454] += 2.5 # í•œë²ˆì˜ ë§¤ìš° ê°•í•œ ì¶©ê²©

    # GPS ì¢Œí‘œ (ì„œìš¸ ì‹œë‚´ë¥¼ ë”°ë¼ ì´ë™í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì‹œë®¬ë ˆì´ì…˜)
    lat = np.linspace(37.5665, 37.5700, num_points)
    lon = np.linspace(126.9780, 126.9820, num_points)
    
    dummy_df = pd.DataFrame({
        'lat': lat, 'lon': lon, # <--- ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½
        'ax': ax, 'ay': ay, 'az': az,
        'gx': gx, 'gy': gy, 'gz': gz, 
        'mx': mx, 'my': my, 'mz': mz
    })
    dummy_df.to_csv(filename, index=False, header=False)

# --------------------------------------------------------------------
# ğŸš€ 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (ìˆ˜ì •ë¨)
# --------------------------------------------------------------------
def load_and_preprocess_data(filepath):
    """
    CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("\n--- 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘ ---")
    
    # CSV íŒŒì¼ ì½ê¸° (ì»¬ëŸ¼ ìˆœì„œ ë³€ê²½)
    col_names = ['lat', 'lon', 'ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz', 'timestamp']
    df = pd.read_csv(filepath, names=col_names, skiprows=1)
    
    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì œê±°
    df.dropna(inplace=True)
    
    # ì´ë™ í‰ê·  í•„í„° ì ìš©
    window_size = 3
    for col in ['ax', 'ay', 'az', 'gx', 'gy', 'gz']:
        df[f'{col}_smooth'] = df[col].rolling(window=window_size).mean()
        
    # ì´ë™ í‰ê·  ê³„ì‚° í›„ ìƒê¸´ ê²°ì¸¡ì¹˜ ë‹¤ì‹œ ì œê±°
    df.dropna(inplace=True)
    
    print("ì „ì²˜ë¦¬ ì™„ë£Œ! ë°ì´í„° ìƒ˜í”Œ:")
    print(df.head(100))
    return df

# --------------------------------------------------------------------
# ğŸ’¡ 2ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ (Feature Engineering) (ìˆ˜ì •ë¨)
# --------------------------------------------------------------------
def extract_features(df, window_size, step_size):
    """
    ì „ì²˜ë¦¬ëœ ë°ì´í„°ì—ì„œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ì´ìš©í•´ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print("\n--- 2ë‹¨ê³„: íŠ¹ì§• ì¶”ì¶œ ì‹œì‘ ---")
    
    features_list = []
    
    for i in range(0, len(df) - window_size, step_size):
        window = df.iloc[i : i + window_size]
        
        # --- íŠ¹ì§• ê³„ì‚° ---
        z_acc_var = window['az_smooth'].var()
        y_acc_mean = window['ay_smooth'].mean()
        
        norm = np.sqrt(window['ax_smooth']**2 + window['ay_smooth']**2 + window['az_smooth']**2)
        norm[norm == 0] = 1e-6
        cos_theta = np.clip(window['az_smooth'] / norm, -1.0, 1.0)
        pitch_rad = np.arccos(cos_theta)
        mean_pitch = np.mean(pitch_rad)

        # extract_features í•¨ìˆ˜ ë‚´ë¶€ì˜ find_peaks ë¼ì¸ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
        # ìµœì†Œ 0.3 ì´ìƒì˜ ë†’ì´ë¥¼ ê°€ì§€ë©°, ìµœì†Œ 15 ë°ì´í„° í¬ì¸íŠ¸ ì´ìƒ ë–¨ì–´ì§„ í”¼í¬ë§Œ ì°¾ê¸°
        peaks, _ = find_peaks(window['az_smooth'], height=0.3)
        num_peaks = len(peaks)

        # extract_features í•¨ìˆ˜ ë‚´ë¶€ì˜ íŠ¹ì§• ê³„ì‚° ë¶€ë¶„ì— ì¶”ê°€í•©ë‹ˆë‹¤.
        z_acc_range = window['az_smooth'].max() - window['az_smooth'].min()
        
        # --- ê²°ê³¼ ì €ì¥ ---
        features = {
            'window_index': i,            # <--- 'start_time' ëŒ€ì‹  ìœˆë„ìš° ì‹œì‘ ì¸ë±ìŠ¤ ì €ì¥
            'z_acc_variance': z_acc_var,
            'y_acc_mean': y_acc_mean,
            'z_acc_range': z_acc_range,
            'mean_pitch': mean_pitch,
            'num_peaks': num_peaks,
            'lat': window['lat'].median(),
            'lon': window['lon'].median()
        }
        features_list.append(features)
        
    feature_df = pd.DataFrame(features_list)
    print("íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ! ì¶”ì¶œëœ íŠ¹ì§• ìƒ˜í”Œ:")
    print(feature_df.head())
    return feature_df

# --------------------------------------------------------------------
# ë©”ì¸ ì½”ë“œ ì‹¤í–‰
# --------------------------------------------------------------------
if __name__ == "__main__":
    # 0ë‹¨ê³„: í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
    # create_dummy_data(FILE_PATH)
    
    # 1ë‹¨ê³„ ì‹¤í–‰
    preprocessed_df = load_and_preprocess_data(FILE_PATH)
    
    # 2ë‹¨ê³„ ì‹¤í–‰
    feature_df = extract_features(preprocessed_df, window_size=10, step_size=5)

    print("\n\nâœ… ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì´ {len(feature_df)}ê°œì˜ íŠ¹ì§• ì„¸íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")


    feature_df['z_acc_variance'].plot(figsize=(15, 5), marker='o')
    plt.title('Z-axis Variance over Time (All Windows)')
    plt.xlabel('Window Sequence')
    plt.ylabel('Variance')
    plt.grid(True)
    plt.show()